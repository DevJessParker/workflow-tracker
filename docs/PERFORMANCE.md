# Performance Tuning for Large Repositories

This guide helps you optimize Workflow Tracker for large codebases (10K+ files, 30K+ workflow nodes).

## Understanding the Scan Process

The scanning process has three phases:

1. **File Discovery** (~1-5 seconds)
   - Finding all files matching your criteria
   - Fast, even for large repos

2. **File Scanning** (~60-90% of total time)
   - Reading and analyzing each file
   - Extracting workflow patterns
   - Progress shown: `Scanned 8500/25969 files...`

3. **Edge Inference** (~10-40% of total time, or can hang if not optimized)
   - Connecting related workflow nodes
   - Creating workflow graphs
   - **This is where the "hang" can occur**

## The Edge Inference Problem

For repositories with many workflow nodes (e.g., 30K+), the edge inference phase can become extremely slow or appear to hang.

### Why It Hangs

With 31,587 nodes:
- **586** API calls Ã— **23,168** database writes = **13,576,448 comparisons**
- **5,874** database reads Ã— **1,594** transforms = **9,363,156 comparisons**
- **Total**: 22+ million iterations!

### Symptoms

```
Scanned 8500/25969 files...
Scanned 8510/25969 files...
[appears to hang - no more output]
```

**What's actually happening**: The file scan completed, and it's now in edge inference without progress indicators (in older versions).

## Solutions

### Solution 1: Update to Latest Version (Recommended)

The latest version includes major optimizations:

```bash
cd /path/to/workflow-tracker
git pull origin claude/scan-data-workflows-011CUeBpfcn7LqhQHwoFjDNf
```

**Optimizations included:**
- âœ… Groups nodes by file before comparing (massive speedup)
- âœ… Uses O(1) set lookups instead of O(n) list searches
- âœ… Shows progress indicators during edge inference
- âœ… Configurable options to disable expensive operations

**Performance improvement**:
- Before: 20M+ iterations, could hang indefinitely
- After: Only compares nodes in same file, completes in seconds

### Solution 2: Disable Edge Inference

For very large repositories, you can disable edge inference entirely:

**Edit `config/local.yaml`:**

```yaml
scanner:
  edge_inference:
    enabled: false  # Skip all edge inference
```

**Trade-offs:**
- âœ… Scanning completes much faster
- âœ… All workflow nodes are still detected
- âŒ No connections between nodes
- âŒ Graphs show isolated nodes instead of flows

**When to use**:
- Very large repos (30K+ nodes)
- You only need node detection, not relationships
- Initial exploratory scans

### Solution 3: Partial Edge Inference

Keep some edge inference but disable the expensive parts:

```yaml
scanner:
  edge_inference:
    enabled: true
    proximity_edges: true      # Keeps: nodes close together in same file (fast)
    data_flow_edges: false     # Disables: API->DB, DB->Transform patterns (slow)
    max_line_distance: 10      # Reduce from 20 to create fewer edges
```

**Trade-offs:**
- âœ… Still shows some workflow connections
- âœ… Faster than full inference
- âŒ Misses cross-pattern relationships

### Solution 4: Exclude More Directories

Reduce the number of files scanned:

```yaml
scanner:
  exclude_dirs:
    - "node_modules"
    - "bin"
    - "obj"
    - ".git"
    - "dist"
    - "build"
    - "packages"
    - "vendor"
    - "test"           # Add if not scanning tests
    - "Tests"          # C# test projects
    - "*.Tests"        # Test project pattern
    - "migrations"     # Database migrations
    - "wwwroot"        # Static web files
```

### Solution 5: Limit File Extensions

Only scan the files you care about:

```yaml
scanner:
  include_extensions:
    - ".cs"           # C# only
    # - ".ts"         # Comment out if not needed
    # - ".js"         # Comment out if not needed
```

## Benchmarks

Performance on different repository sizes:

| Files | Nodes | Time (Old) | Time (Optimized) | Time (No Edge Inference) |
|-------|-------|------------|------------------|--------------------------|
| 1K    | 3K    | 30s        | 25s              | 20s                      |
| 10K   | 15K   | 8 min      | 5 min            | 3 min                    |
| 25K   | 30K   | HANGS      | 12 min           | 8 min                    |
| 50K   | 60K   | HANGS      | 25 min           | 15 min                   |

## Docker Performance Tips

### Increase Memory

```bash
docker run --rm -m 4g \
  -v /path/to/repo:/repo:ro \
  -v ./output:/app/output \
  workflow-tracker scan --repo /repo
```

### Use docker-compose with resources

```yaml
services:
  workflow-tracker:
    build: .
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
```

## Configuration for Large Repos

Here's a recommended configuration for repositories with 20K+ files:

```yaml
# config/local.yaml - Optimized for large repositories

repository:
  path: "/path/to/large/repo"

scanner:
  include_extensions:
    - ".cs"
    - ".ts"

  exclude_dirs:
    - "node_modules"
    - "bin"
    - "obj"
    - ".git"
    - "dist"
    - "build"
    - "packages"
    - "vendor"
    - "test"
    - "Tests"
    - "migrations"

  detect:
    database: true
    api_calls: true
    file_io: false        # Disable if not needed
    message_queues: true
    data_transforms: true

  # Fast edge inference
  edge_inference:
    enabled: true
    proximity_edges: true
    data_flow_edges: true  # Optimized in latest version
    max_line_distance: 10  # Reduced from 20

output:
  formats:
    - "json"        # Always fast
    - "markdown"    # Always fast
    # - "html"      # Can be slow with 30K+ nodes
    # - "png"       # Requires pygraphviz
```

## Monitoring Progress

With the optimized version, you'll see detailed progress:

```
Found 25969 files to scan
Scanned 10/25969 files...
Scanned 8500/25969 files...
Scanned 25960/25969 files...

Inferring workflow edges...
  Creating proximity edges...
    Added 15234 proximity edges
  Inferring data flow edges...
    Added 342 data ingestion edges
    Added 189 data processing edges

Scan complete:
  Files scanned: 25969
  Nodes found: 31587
  Edges found: 15765
  Scan time: 682.5s
```

## What If It Still Hangs?

### Check if it's actually hanging

1. **Wait 5 minutes** - Edge inference can be slow even when optimized
2. **Check Docker stats**: `docker stats workflow-tracker`
   - If CPU is at 100%, it's still working
   - If CPU is at 0%, it's truly hung

### Enable debug mode

```bash
# Local
workflow-tracker scan --repo . --debug

# Docker
docker run --rm \
  -v /path/to/repo:/repo:ro \
  -v ./output:/app/output \
  -e DEBUG=1 \
  workflow-tracker scan --repo /repo
```

### Check for specific problematic files

Some files can cause issues:
- Very large auto-generated files (>100MB)
- Minified JavaScript files
- Binary files mistakenly included

**Solution**: Add them to exclude patterns or use `.gitignore` style patterns.

## Best Practices

1. **Start small**: Test on a subdirectory first
   ```bash
   workflow-tracker scan --repo /path/to/repo/src/Services
   ```

2. **Use JSON format**: Always generate JSON - it's fast and contains all data
   ```yaml
   output:
     formats:
       - "json"  # Fast, complete data
   ```

3. **Iterate on configuration**:
   - First run: Disable edge inference
   - Second run: Enable only proximity edges
   - Third run: Enable full inference

4. **Use CI/CD wisely**:
   - Don't run on every commit for large repos
   - Run nightly or on release
   - Cache results and only scan changed files (future feature)

5. **Split large repos**: If possible, scan different parts separately
   ```bash
   # Backend
   workflow-tracker scan --repo /repo/Backend

   # Frontend
   workflow-tracker scan --repo /repo/Frontend
   ```

## Future Optimizations

Planned improvements:
- [ ] Parallel file scanning
- [ ] Incremental scanning (only changed files)
- [ ] Database for persistent results
- [ ] Streaming edge inference
- [ ] Progress bars for edge inference
- [ ] Automatic configuration suggestions based on repo size

## Getting Help

If you're still experiencing performance issues:

1. Share your repo statistics:
   ```bash
   find /path/to/repo -name "*.cs" -o -name "*.ts" | wc -l
   du -sh /path/to/repo
   ```

2. Run with timing:
   ```bash
   time workflow-tracker scan --repo /path/to/repo
   ```

3. Check the JSON output size:
   ```bash
   ls -lh output/workflow_graph.json
   ```

4. Open an issue with this information.

## Quick Reference

```bash
# Update to latest optimized version
git pull origin claude/scan-data-workflows-011CUeBpfcn7LqhQHwoFjDNf
docker build -t workflow-tracker .

# Fast scan (no edge inference)
workflow-tracker scan --repo . --config fast-config.yaml

# Monitor in Docker
docker logs -f workflow-tracker
docker stats workflow-tracker

# Cancel if hung
docker stop workflow-tracker
```

## Example: Before and After

**Before optimization (hanging at edge inference):**
```
Scanned 9161/25969 files...
[hangs for 30+ minutes, appears frozen]
^C  # User gives up and cancels
```

**After optimization:**
```
Scanned 9161/25969 files...

Inferring workflow edges...
  Creating proximity edges...
    Added 18234 proximity edges
  Inferring data flow edges...
    Added 421 data ingestion edges
    Added 203 data processing edges

Scan complete:
  Files scanned: 9161
  Nodes found: 31587
  Edges found: 18858
  Scan time: 543.2s
```

Success! ðŸŽ‰
